{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "- It is not allowed for you to use packages other than the specified packages below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Logistic Regression [15 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load Dataset [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the csv file,'final_shuffled_breast_cancer100.csv' as `df`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file,'final_shuffled_breast_cancer100.csv' as df\n",
    "df = pd.read_csv(\"final_shuffled_breast_cancer100.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Split the independent variable set and the target variable set [2 points]\n",
    "- Assign `X` to the independent variable dataset\n",
    "- Assign `y` to the target variable dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"target\", axis =1)\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Split Dataset into the train & testset [2 points]\n",
    "** When you use scikit-learn method to split the train & test set : \n",
    "- the `random_state` value has to be zero.\n",
    "- the ratio of train set and test set is as follows : 75% train set / 25% test set\n",
    "- Assign the variable names as follow : `X_train`, `X_test`, `y_train`, `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Standirdize the dataset by \"StandardScaler\" method of scikit-learn [4 points]\n",
    "- Use the method as the default state\n",
    "- Fit the `StandardScaler` on your training data only, then standardize both training and test sets using that scaler. The reason we fit a scaler on training set is to avoid possible information leakage from the test dataset. Test dataset should always remain \"Unseen\" until the testing phase. Thus, we should always scale using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Load and train a logistic regression model by scikit-learn. [2 points]\n",
    "- Intercept term should be included for training\n",
    "- Assign LogisticRegression as `model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Print the coefficient & intercept of your model [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.63330582 -0.38463901 -0.62188958 -0.58284847 -0.0124785  -0.22911522\n",
      "  -0.36758627 -0.49012322  0.30941314  0.01812234 -0.23837422  0.4929945\n",
      "  -0.19928741 -0.31225956  0.33192808 -0.01874974  0.03158852  0.19551406\n",
      "   0.19597145 -0.02103781 -0.68210684 -0.5961599  -0.63460298 -0.57103766\n",
      "  -0.3021311  -0.44437018 -0.51058829 -0.4010555  -0.36812328 -0.44266915]]\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13838155]\n"
     ]
    }
   ],
   "source": [
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Predict and evaluate the model on your test set [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 point]\n",
    "- Predict class labels of the test set using the trained model (Deterministic Label)\n",
    "- Print the predicted labels of test set and assign it to `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "# print the predicted labels of test set\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 point]\n",
    "- Evaluate the trained model using 'accuracy_score' metric on the test set.\n",
    "(Evaluate how well the predicted label of the test set matches the actual correct answer value.)\n",
    "- Print the accuracy score value\n",
    "(the 'accuracy_score' method has been already imported.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy score on your test set\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. PCA [15 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Load PCA instance and reduce the dimension of train and test set [5 points] \n",
    "\n",
    "- Load the `PCA` model as the default state\n",
    "- Reuse the train set standardized with the `StandardScaler` as the input data of the PCA.\n",
    "- You should fit the PCA instance by the standardized train set. \n",
    "- Transform(train) your train data and test data by principal components created by train set.\n",
    "\n",
    "- Reduce dimensions of train and test set from 30 to 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit your PCA model with your train set, and transform both train & test set by the fitted PCA\n",
    "pca = PCA()\n",
    "pca = pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_train = X_train[:,:2]\n",
    "X_test = X_test[:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Return the percentage of variance explained by the selected components. [3 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49263364, 0.19922127])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Return the accumulated  sum of percentage of variance explained by the selected components, which you calculated in Task #2.2. [2 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49263364, 0.69185491])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_[0:2].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Plot graph [5 points]\n",
    "- Plot the dimensionally reduced \"train data points\" using the `matplotlib.pyplot` library\n",
    "- The meaning of dependent variable is such as: \n",
    "-    1 : positive (breast cancer)\n",
    "-    0 : negative (breast cancer)\n",
    "- For label 1 and label 0, plot those labels by assigning different colors or symbols.\n",
    "- Refer to the below pictures as examples (There is no need to exactly imitate the image below.)\n",
    "- Recommend to use `plt.scatter` function (You are allowed to use another function as well.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Hints]\n",
    "\n",
    "##### [step 1] Make a DataFrame consisting of three columns such as 'PC1', 'PC2', 'dependent variable' which have already been made on Task No. 2.1\n",
    "\n",
    "##### [step 2] Divide the previously created data frame into TWO DataFrames \n",
    "- A DataFrame containing only data corresponding to 'dependent variable 0'. (including 'PC1', 'PC2', 'dependent variable 0')  \n",
    "- A DataFrame containing only data corresponding to 'dependent variable 1'. (including 'PC1', 'PC2', 'dependent variable 1')\n",
    "\n",
    "##### [step 3] Draw a Scatter plot showing the PC SCOREs with different colors depending on the dependent variable.\n",
    "- Use `plt.scatter' function\n",
    "- Refer to the content:\n",
    "https://pythonspot.com/matplotlib-scatterplot/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8808562670>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"PC1\":X_train[:,0],\"PC2\":X_train[:,1], \"dependent variable\":y_train})\n",
    "df_zeros = df[df[\"dependent variable\"]==0]\n",
    "df_ones= df[df[\"dependent variable\"]==1]\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df_zeros[\"PC1\"],df_zeros[\"PC2\"],c=\"blue\", label = \"negative\")\n",
    "ax.scatter(df_ones[\"PC1\"],df_ones[\"PC2\"],c=\"orange\", label = \"positive\")\n",
    "ax.set(xlabel=\"pca_component1\",ylabel=\"pca_component2\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Train and test another Logistic Regression model after PCA [10 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Load another logistic regression model [5 points]\n",
    "- Load the logistic regression model as `model2`\n",
    "- Train the model by the dimensionally reduced train set by PCA before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Predict and evaluate the model on your test setÂ¶ [3 points]\n",
    "- Predict class labels of test set by using the trained model (Not probabilities) [2 points]\n",
    "- Print the predicted labels of test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "# print the predicted labels of test set [2 points]\n",
    "y_preds = model2.predict(X_test)\n",
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate the trained model using 'accuracy_score' metric. (the 'accuracy_score' method has been already imported.) [1 points]\n",
    "- Print the accuracy score value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the accuracy score on your test set [1 points]\n",
    "accuracy_score(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Analysis\n",
    "- Compare the `accuracy_score` of the logistic regression model that you trained **first**(`model`) with the `accuracy_score` of the logical regression model that you trained newly **after reducing its dimension by PCA technique**(`model2`), and describe why you think the result is different. (Please describe your answer in 2-3 sentences) [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we get better result is because by reducing the dimensionality, we got rid of variables that are highly correlated. As an example, in this dataset, we have ```radius error``` and ```area error```. Obviously, they depend on each other. The more the value of ```radius error``` is, the higher the value of ```area error``` is. This implies that the assumption of independent variables is violated in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
