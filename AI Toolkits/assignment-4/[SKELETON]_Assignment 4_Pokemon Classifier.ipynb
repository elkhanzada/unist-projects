{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnFvUsHEH7P_"
      },
      "source": [
        "## Download data and source folder (**Do not Modify**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ExnLFOzGrz8",
        "outputId": "e72369ae-52bd-4437-89d9-321d839c7574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CQdgTOUlY-TUoWZyxtVZxRthBhSuhDVi\n",
            "To: /content/source.zip\n",
            "100%|██████████| 11.8M/11.8M [00:00<00:00, 45.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "import gdown\n",
        "import zipfile\n",
        "url = 'https://drive.google.com/uc?id=1CQdgTOUlY-TUoWZyxtVZxRthBhSuhDVi'\n",
        "output = 'source.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "with zipfile.ZipFile(output, \"r\") as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0SUiITHIODO"
      },
      "source": [
        "## Install package for calculating FLOPS (**Do not Modify**)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bYv2QizG2Uf",
        "outputId": "b6b5a067-892f-453e-a4b2-9b9d0f65c3f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pthflops\n",
            "  Downloading pthflops-0.4.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pthflops) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pthflops) (4.1.1)\n",
            "Installing collected packages: pthflops\n",
            "Successfully installed pthflops-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pthflops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxutNkHbIVDy"
      },
      "source": [
        "## Import Necessary Dependencies\n",
        "- You may import other packages if you want.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iO9f0-7-HJT2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import os.path as osp\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pthflops import count_ops\n",
        "\n",
        "# functions that you downloaded from the first code cell.\n",
        "# please use this code for seed reset, dataloaders, and test function  \n",
        "from src.util import reset\n",
        "# if data.py is changed, please submit that also.\n",
        "from src.data import get_dataloader\n",
        "from src.test import test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwrUU3z-IuJb"
      },
      "source": [
        "## Define label names, data directory, device name.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5cYoZDUKHxHy"
      },
      "outputs": [],
      "source": [
        "## DO NOT MODIFY FROM HERE\n",
        "label_names = ['bug', 'electric', 'fighting', 'fire', 'flying', 'grass', 'ground', 'phychic', 'poison', 'water']\n",
        "data_dir = 'data'\n",
        "## DO NOT MODIFY UNTIL HERE\n",
        "\n",
        "## You may modify device name depending on your workspace spec.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "## Specify the batch size as you want.\n",
        "batch_size = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc8zxrr7JBep"
      },
      "source": [
        "## **(TO-DO)** DEFINE YOUR `MyModel`\n",
        "- Please do not change the class name. Let `MyModel` be your classifier class name. \n",
        "- Below is just simple example using ResNet18."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UBeaeUcsH0P2"
      },
      "outputs": [],
      "source": [
        "######## Define your classification model.  #######\n",
        "# below model is not valid anymore since it uses ResNet.\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, dim_output=len(label_names)):\n",
        "        super().__init__()        \n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 20, kernel_size=(5,5), padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(20, 40, kernel_size=(3,3), padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(40*28*28, dim_output)\n",
        "        )\n",
        "        \n",
        "    def forward(self, img):\n",
        "        B, C, H, W = img.shape\n",
        "\n",
        "        out = self.features(img)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)    \n",
        "        return F.softmax(out)\n",
        "####################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFYTeLz1KOGS"
      },
      "source": [
        "## **(Optional)** Make your own loss function.\n",
        "- You may change `criterion` as you want. \n",
        "- But make your custom loss function work without changing below lines, which starts from `model.train()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M4ed9AWoH0yC"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, sample):\n",
        "    ### You may define your own loss function.###\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #############################################\n",
        "\n",
        "    ### make your code work without changing below lines ###\n",
        "    model.train()    \n",
        "    \n",
        "    input = sample['img'].float().to(device)\n",
        "    label = sample['label'].long().to(device)\n",
        "\n",
        "    pred = model(input)\n",
        "\n",
        "    loss = criterion(pred, label)\n",
        "\n",
        "    num_correct = torch.sum(torch.argmax(pred, dim=-1)==label)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), num_correct.item()\n",
        "    ##########################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1Szzew1Mbfl"
      },
      "source": [
        "## **(TO-DO)** DEFINE YOUR `get_optimizer`\n",
        "- Please do not change the function name. Let `get_optimizer` be your classifier class name. \n",
        "- This function should return the optimizer for optimizing model parameters properly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dxBrwyvMMXN9"
      },
      "outputs": [],
      "source": [
        "######## Define your own function for optimizer.  #######\n",
        "def get_optimizer(model, lr=1e-4, wd=1e-6):\n",
        "    return optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "##########################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOgJFjMSLV7X"
      },
      "source": [
        "## Repeat Training with different 10 random seeds.\n",
        "\n",
        "*   Do not change `max_epoch` and `num_seeds`.\n",
        "*   You  may change lines for `MyModel` and `get_optimizer` part if they require additional inputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbowrzBxH06d",
        "outputId": "1fff9c61-1a11-4783-ec77-3f5b65b0d586"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-cc0bd8744efc>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(out)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<<<<<[SEED 0] BEST ACCU : 0.5349397590361452>>>>>\n",
            "<<<<<[SEED 1] BEST ACCU : 0.5493975903614456>>>>>\n",
            "<<<<<[SEED 2] BEST ACCU : 0.46987951807228945>>>>>\n",
            "<<<<<[SEED 3] BEST ACCU : 0.5614457831325298>>>>>\n",
            "<<<<<[SEED 4] BEST ACCU : 0.5228915662650605>>>>>\n",
            "<<<<<[SEED 5] BEST ACCU : 0.5469879518072295>>>>>\n",
            "<<<<<[SEED 6] BEST ACCU : 0.5180722891566271>>>>>\n",
            "<<<<<[SEED 7] BEST ACCU : 0.4771084337349403>>>>>\n",
            "<<<<<[SEED 8] BEST ACCU : 0.542168674698795>>>>>\n",
            "<<<<<[SEED 9] BEST ACCU : 0.4698795180722898>>>>>\n"
          ]
        }
      ],
      "source": [
        "### Do not change below parameters ###\n",
        "max_epoch = 5\n",
        "num_seeds = 10\n",
        "### Do not change above parameters ###\n",
        "\n",
        "\n",
        "### Make your code work without changing below lines except for \"optimizer\" part ###\n",
        "total_best_accu = []\n",
        "\n",
        "for seed in range(num_seeds):\n",
        "    # do not erase this random seed initialization part\n",
        "    reset(seed)\n",
        "\n",
        "    # get dataloader by spliting train/test data randomly.\n",
        "    train_loader, test_loader, train_dataset, test_dataset = get_dataloader(data_dir, label_names, batch_size)\n",
        "\n",
        "    # you may change below line for model definition if your \"MyModel\" requires more inputs.\n",
        "    model = MyModel().to(device)\n",
        "\n",
        "    # you may change below line for optimizer if your \"get optimizer\" requires more inputs.\n",
        "    optimizer = get_optimizer(model)\n",
        "\n",
        "    ###### do not change below lines. Make your code work with below lines. ####\n",
        "    best_accu = -100\n",
        "    for epoch in range(max_epoch):\n",
        "        avg_tr_loss = 0.0\n",
        "        avg_tr_correct = 0.0\n",
        "        for sample in train_loader:\n",
        "            tr_loss, tr_correct = train(model, optimizer, sample)\n",
        "\n",
        "            avg_tr_loss += tr_loss / len(train_loader)\n",
        "            avg_tr_correct += tr_correct / len(train_dataset)\n",
        "\n",
        "        avg_te_correct = 0.0\n",
        "        for sample in test_loader:\n",
        "            te_correct = test(model, sample, device)\n",
        "            avg_te_correct += te_correct / len(test_dataset)\n",
        "    \n",
        "        best_accu = max(avg_te_correct, best_accu)\n",
        "\n",
        "    print('<<<<<[SEED {}] BEST ACCU : {}>>>>>'.format(seed, best_accu))    \n",
        "    total_best_accu.append(best_accu)\n",
        "    if seed < num_seeds-1:\n",
        "        del model, optimizer\n",
        "    ############################################################################   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAXeguQhNtLr"
      },
      "source": [
        "## Calculate your grade **(Do not Modify)**\n",
        "- Grade is calculated based on your `average best accuracy` and `FLOPS`.\n",
        "- Higher accuracy and lower flops make your grade better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkYU6njOH1Dl",
        "outputId": "bff82e94-a16c-4d28-d02d-d74129576daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input size: (1, 3, 112, 112)\n",
            "43,120,010 FLOPs or approx. 0.04 GFLOPs\n",
            "**************************************************\n",
            "Mean Accuracy : 0.5192771084337352\n",
            "Accuracy Point: 0.6303716057251455\n",
            "**************************************************\n",
            "Flops:  43120010\n",
            "Flops Advantage:  0.8226389921586462\n",
            "**************************************************\n",
            "Total Points :  0.5185682624191612\n",
            "YOUR grade is 50 point\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pthflops/ops_fx.py:219: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = target(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "###### do not change below lines #####\n",
        "num_ops = count_ops(model, torch.rand(1, 3, 112, 112).to(device), verbose=False)\n",
        "\n",
        "mean_accu = np.mean(total_best_accu)\n",
        "accu_thres = 0.75\n",
        "accu_point = min(1, np.exp(-2*(accu_thres-mean_accu)))\n",
        "\n",
        "flops = num_ops[0]\n",
        "flops_thres = 2e8\n",
        "flop_disadvantage = flops_thres / (flops_thres + flops)\n",
        "\n",
        "print('*'*50)\n",
        "print('Mean Accuracy :', mean_accu)\n",
        "print('Accuracy Point:', accu_point)\n",
        "print('*'*50)\n",
        "print('Flops: ', flops)\n",
        "print('Flops Advantage: ', flop_disadvantage)\n",
        "print('*'*50)\n",
        "\n",
        "point = accu_point * flop_disadvantage\n",
        "print('Total Points : ', point)\n",
        "\n",
        "threshold = 0.5\n",
        "max_point = 50\n",
        "\n",
        "if point > threshold:\n",
        "    grade = max_point\n",
        "else:\n",
        "    grade = np.exp(-2*(threshold - point)) * max_point\n",
        "\n",
        "print('YOUR grade is {} point'.format(grade))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.10 ('pdl')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "d19aa5a20e88fe80248d4b0c2d7d27a7c9d54896ad8b5c06765854ce70c72cb9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
